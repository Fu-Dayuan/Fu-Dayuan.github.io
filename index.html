<html>

<head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-EWB73JXBN5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-EWB73JXBN5');
</script>
	
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
	<meta name="description" content="Homepage of Dayuan-Fu">
	<link rel="stylesheet" href="./files/jemdoc.css" type="text/css">
	<title>Dayuan Fu's Homepage|傅大源的个人主页</title>
</head>


<body>

<div id="layout-content" style="margin-top:25px">

<table><tbody><tr>
    <td width="670">
        <div id="toptitle"><h1>Dayuan Fu (傅大源)&nbsp;</h1></div>
        <h3>M.S. Student</h3>  
        <p>
            Dept. of Artificial Intelligence <br>
            Beijing University of Posts and Telecommunications (BUPT) <br>
            Beijing, China. <br>
	    WeChat: fudayuan2000 <br>
            Email:  <a href="mailto:fdy@bupt.edu.cn">fdy@bupt.edu.cn</a> <br>
		
            <a href="https://github.com/Fu-Dayuan">[Github]</a>
            <a href="https://scholar.google.com/citations?hl=zh-CN&user=8t2DPs0AAAAJ">[Google Scholar]</a>
            <a href="https://www.semanticscholar.org/author/Dayuan-Fu/2187926603">[Semantic Scholar]</a> 
            <a href="https://dblp.org/pid/331/3042.html">[DBLP]</a> 

        </p>
    </td>

    <td><img src="./files/photo.jpg" border="0" width="120"></td>
</tr></tbody></table>


<h2>About</h2>
    <p> I am Dayuan Fu, a graduate student at <a href="https://pris-nlp.github.io/en/author/dayuan-fu/">PRIS-NLP Group</a> at Beijing University of Posts and Telecommunications (BUPT), supervised by <a href="https://pris-nlp.github.io/en/author/weiran-xu/">Prof. Weiran Xu.</a> I visited <a href="https://c3i.ee.tsinghua.edu.cn/author/%E5%82%85%E5%A4%A7%E6%BA%90/">TsinghuaC3I group</a> from 2022.10 to 2024.8. My research interests primarily focus on large language model agents, including both training-based and prompt-based approaches. For prompt-based approaches, I am concentrating on improving memory mechanisms. For training-based approaches, my focus is on agent generalization, such as creating a world model to handle diverse problems. Additionally, I am interested in reasoning, exemplified by projects like DeepSeek-Prover. I have published several papers at prominent NLP conferences, including EMNLP, CIKM, and NAACL.</p>
	    
<h2>News</h2>
<ul>
    <li><strong>[2024-09]</strong>  Two papers have been accepted by EMNLP 2024! </li>
    <li><strong>[2024-03]</strong>  Two papers have been accepted by NAACL 2024!</li>
    <li><strong>[2024-02]</strong> One paper has been accepted by LREC-COLING 2024! </li>
    <li><strong>[2023-08]</strong> One paper has been accepted by CIKM 2023! </li>
    <li><strong>[2024-02]</strong> One paper have been accepted by NAACL 2024! </li>
    <li><strong>[2023-02]</strong> Two papers have been accepted by ICASSP 2023! </li>
    <li><strong>[2022-10]</strong> One paper has been accepted at the SereTOD 2022 Workshop, EMNLP 2022! </li>
    <li><strong>[2022-09]</strong> Achieved the 1st rank on SereTOD 2022 track 2, EMNLP 2022!</li>
</ul>
    


<h2>Experiences</h2>
	<strong>Academia</strong>
	<ul>
        <li>[2023.9 - Now]<img style="width: 1em;"src="./files/bupt.webp"> M.S. at Beijing University of Posts and Telecommunications</li>
	    <li>[2019.9 - 2023.6] <img style="width: 1em;"src="./files/bupt.webp"> B.S. at Beijing University of Posts and Telecommunications</li>
        <li>[2022.9 - 2023.9] <img style="width: 1em;"src="./files/C3I.jpg"> Visiting student at TsinghuaC3I, Tsinghua University</li>
</ul>
	
 	<strong>Industry</strong>
	<ul>
	<li>[2024.1 - Now] <img style="width: 2.4em;"src="./files/meituan.png"> Meituan, NLP Center, Research Intern on Agent and data synthesis.</li>
</ul>

<h2>Featured Preprints</h2>
	
<strong>-2024-</strong>



<!-- <ul><li><p><img src="./files/qwen_logo.webp" style="width: 1em;" /> Qwen2 Technical Report<br />
    An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li, Chengyuan Li, Dayiheng Liu, Fei Huang, <strong>Guanting Dong</strong>, Haoran Wei, Huan Lin, Jialong Tang, Jialin Wang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Ma, Jin Xu, Jingren Zhou, Jinze Bai, Jinzheng He, Junyang Lin, Kai Dang, Keming Lu, Keqin Chen, Kexin Yang, Mei Li, Mingfeng Xue, Na Ni, Pei Zhang, Peng Wang, Ru Peng, Rui Men, Ruize Gao, Runji Lin, Shijie Wang, Shuai Bai, Sinan Tan, Tianhang Zhu, Tianhao Li, Tianyu Liu, Wenbin Ge, Xiaodong Deng, Xiaohuan Zhou, Xingzhang Ren, Xinyu Zhang, Xipin Wei, Xuancheng Ren, Yang Fan, Yang Yao, Yichang Zhang, Yu Wan, Yunfei Chu, Yuqiong Liu, Zeyu Cui, Zhenru Zhang, Zhihao Fan<br />
    Arxiv.
    <a href='https://arxiv.org/pdf/2407.10671'>[paper]</a >
	<a href='https://github.com/QwenLM/Qwen2'>[code]</a >
    <a href='https://huggingface.co/Qwen'>[model]</a >
    <a href='https://qwenlm.github.io/blog/qwen2/'>[blog]</a><br>
</li>
</ul>


<ul><li><p>Understand What LLM Needs: Dual Preference Alignment for Retrieval-Augmented Generation<br />
    <strong>Guanting Dong</strong>, Yutao Zhu, Chenghao Zhang, Zechen Wang, Zhicheng Dou, Ji-Rong Wen<br />
    Arxiv.
    <a href='https://arxiv.org/pdf/2406.18676'>[paper]</a >
	<a href='https://github.com/dongguanting/DPA-RAG'>[code]</a >
    <a href='https://mp.weixin.qq.com/s/GddtwVZBWlGVpugVHTjUOQ'>[blog]</a><br>
</li>
</ul>


<ul><li><p>We-Math: Does Your Large Multimodal Model Achieve Human-like Mathematical Reasoning?<br />
    Runqi Qiao, Qiuna Tan, <strong>Guanting Dong</strong>, Minhui Wu, Chong Sun, Xiaoshuai Song, Zhuoma GongQue, Shanglin Lei, Zhe Wei, Miaoxuan Zhang, Runfeng Qiao, Yifan Zhang, Xiao Zong, Yida Xu, Muxi Diao, Zhimin Bao, Chen Li, Honggang Zhang<br />
    Arxiv.
    <a href='https://arxiv.org/pdf/2407.01284'>[paper]</a >
	<a href='https://we-math.github.io/'>[website]</a >
	<a href='https://github.com/We-Math/We-Math'>[code]</a >
	<a href='https://huggingface.co/datasets/We-Math/We-Math'>[dataset]</a >
    <a href='https://mp.weixin.qq.com/s/uU1lZV0Ymj31cmZryhffyQ'>[blog]</a><br>
</li>
</ul>


<ul><li><p>CS-Bench: A Comprehensive Benchmark for Large Language Models towards Computer Science Mastery<br />
    Xiaoshuai Song, Muxi Diao, <strong>Guanting Dong</strong>, Zhengyang Wang, Yujia Fu, Runqi Qiao, Zhexu Wang, Dayuan Fu, Huangxuan Wu, Bin Liang, Weihao Zeng, Yejie Wang, Zhuoma GongQue, Jianing Yu, Qiuna Tan, Weiran Xu<br />
    Arxiv.
    <a href='https://arxiv.org/pdf/2406.08587'>[paper]</a >
	<a href='https://csbench.github.io/'>[website]</a >
	<a href='https://github.com/csbench/csbench'>[code]</a >
	<a href='https://huggingface.co/datasets/CS-Bench/CS-Bench'>[dataset]</a >
    <a href='https://mp.weixin.qq.com/s/9DDSbKJt3rYisJi95fJ46w'>[blog]</a><br>

</li>
</ul>

<ul><li><p>DotaMath: Decomposition of Thought with Code Assistance and Self-correction for Mathematical Reasoning<br />
    Chengpeng Li, <strong>Guanting Dong</strong>, Mingfeng Xue, Ru Peng, Xiang Wang, Dayiheng Liu<br />
    Arxiv.
    <a href='https://arxiv.org/pdf/2407.04078'>[paper]</a >
	<a href='https://github.com/ChengpengLi1003/DotaMath'>[code]</a >
    <a href='https://mp.weixin.qq.com/s/pH-A9MuDCCDaeOseeogghQ'>[blog]</a><br>
</li>
</ul>



<ul><li><p>Self-play with Execution Feedback: Improving Instruction-following Capabilities of Large Language Models<br />
    <strong>Guanting Dong</strong>, Keming Lu, Chengpeng Li, Tingyu Xia, Bowen Yu, Chang Zhou, Jingren Zhou<br />
    Arxiv.
    <a href='https://arxiv.org/pdf/2406.13542'>[paper]</a >
	<a href='https://github.com/QwenLM/AutoIF'>[code]</a >
    <a href='https://zhuanlan.zhihu.com/p/707012952'>[blog]</a><br>
</li>
</ul>


<ul><li><p>PreAct: Predicting Future in ReAct Enhances Agent's Planning Ability<br />
Dayuan Fu, Jianzhao Huang, Siyuan Lu, <strong>Guanting Dong</strong>, Yejie Wang, Keqing He, Weiran Xu<br />
    Arxiv. 
    <a href='https://arxiv.org/pdf/2402.11534.pdf'>[paper]</a>
    <a href='https://github.com/Fu-Dayuan/PreAct'>[code]</a> 
	<a href='https://mp.weixin.qq.com/s/1R_0Q57_vu9uGr_3j0Ozwg'>[blog]</a><br>
</li>
</ul>


<ul><li><p>Knowledge Editing on Black-box Large Language Models<br />
Xiaoshuai Song, Zhengyang Wang, Keqing He, <strong>Guanting Dong</strong>, Jinxu Zhao, Weiran Xu<br />
    Arxiv. 
    <a href='https://arxiv.org/pdf/2402.08631.pdf'>[paper]</a>
	<a href='https://github.com/songxiaoshuai/postEdit'>[code]</a> 
	<a href='https://mp.weixin.qq.com/s/KUIAugOzQzcbfPc4jlGeuQ'>[blog]</a><br>
</li>
</ul>

<strong>-2023-</strong>
	
<ul><li><p>Scaling relationship on learning mathematical reasoning with large language models<br />
    Zheng Yuan, Hongyi Yuan, Chengpeng Li, <strong>Guanting Dong</strong>, Chuanqi Tan, Chang Zhou<br />
    Arxiv. 
    <a href='https://arxiv.org/pdf/2308.01825.pdf'>[paper]</a>
	<a href='https://github.com/OFA-Sys/gsm8k-ScRel'>[code]</a>
	<a href='https://zhuanlan.zhihu.com/p/648000801'>[blog]</a><br>
</li>
</ul>
	

</ul>	

<ul><li><p>InstructERC: Reforming Emotion Recognition in Conversation with a Retrieval Multi-task LLMs Framework<br />
    Shanglin Lei,<strong>Guanting Dong*</strong>, Xiaoping Wang, Keheng Wang, Sirui Wang<br />
    Arxiv. 
    <a href='https://arxiv.org/pdf/2309.11911.pdf'>[paper]</a>
    <a href='https://github.com/LIN-SHANG/InstructERC'>[code]</a> 
	<a href='https://mp.weixin.qq.com/s/Jj4Cf4xDmykeEYTvzNoFYg'>[blog]</a><br>
</li>
</ul>
	 -->
	
<h2>Selected Publications</h2>

(* denotes equal contributions)<br>
<strong>-2024-</strong>
<!-- 

<ul><li><p>How Do Your Code LLMs Perform? Empowering Code Instruction Tuning with High-Quality Data<br />
   Yejie Wang, Keqing He, Dayuan Fu, Zhuoma Gongque, Heyang Xu, Yanxu Chen, Zhexu Wang, Yujia Fu, <strong>Guanting Dong</strong>, Muxi Diao, Jingang Wang, Mengdi Zhang, Xunliang Cai, Weiran Xu<br />
    EMNLP 2024.
    <a href='https://arxiv.org/pdf/2409.03810'>[paper]</a >
	<a href='https://github.com/banksy23/XCoder'>[code]</a >
    <a href='https://mp.weixin.qq.com/s/57gziduRY-H4E3-Da6NgWw'>[blog]</a><br>
</li>
</ul>

	
<ul><li><p>How Abilities in Large Language Models are Affected by Supervised Fine-tuning Data Composition<br />
    <strong>Guanting Dong</strong>, Hongyi Yuan, Keming Lu, Chengpeng Li, Mingfeng Xue, Dayiheng Liu, Wei Wang, Zheng Yuan, Chang Zhou, Jingren Zhou<br />
    ACL 2024.
    <a href='https://arxiv.org/pdf/2310.05492.pdf'>[paper]</a>
	<a href='https://mp.weixin.qq.com/s/3RIBzuVlK0qHbO_Q04s-cw'>[blog]</a><br>
</li>
</ul>

<ul><li><p>MuggleMath: Assessing the Impact of Query and Response Augmentation on Math Reasoning<br />
Chengpeng Li, Zheng Yuan, Hongyi Yuan, <strong>Guanting Dong</strong>, Keming Lu, Jiancan Wu, Chuanqi Tan, Xiang Wang, Chang Zhou<br />
    ACL 2024. 
    <a href='https://arxiv.org/pdf/2310.05506.pdf'>[paper]</a>
	<a href='https://github.com/LHRLAB/ChatKBQA'>[code]</a>
	<a href='https://zhuanlan.zhihu.com/p/663463273'>[blog]</a><br>
</li>
</ul>
	
<ul><li><p>ChatKBQA: A Generate-then-Retrieve Framework for Knowledge Base Question Answering with Fine-tuned Large Language Models
<br />
Haoran Luo, Haihong E, Zichen Tang, Shiyao Peng, Yikai Guo, Wentai Zhang, Chenghao Ma, <strong>Guanting Dong</strong>, Meina Song, Wei Lin<br />
    Findings of ACL 2024. 
    <a href='https://arxiv.org/pdf/2310.08975'>[paper]</a>
	<a href='https://github.com/OFA-Sys/gsm8k-ScRel'>[code]</a>
	<a href='https://mp.weixin.qq.com/s/rBioXGaCefgOJnrkcSOs3A'>[blog]</a><br>
</li>
</ul>
	
<ul><li><p>DolphCoder: Echo-Locating Code Large Language Models with Diverse and Multi-Objective Instruction Tuning<br />
Yejie Wang, Keqing He, <strong>Guanting Dong</strong>, Pei Wang, Weihao Zeng, Muxi Diao, Yutao Mou, Mengdi Zhang, Jingang Wang, Xunliang Cai, Weiran Xu<br />
    ACL 2024.
    <a href='https://arxiv.org/pdf/2402.09136.pdf'>[paper]</a>
</li>
</ul>
	
<ul><li><p>Noise-BERT: A Unified Perturbation-Robust Framework with Noise Alignment Pre-training for Noisy Slot Filling Task<br />
Jinxu Zhao, <strong>Guanting Dong∗</strong>, Yueyan Qiu, Tingfeng Hui, Xiaoshuai Song, Daichi Guo, Weiran Xu<br />
ICASSP 2024. 
<a href='https://arxiv.org/pdf/2402.14494.pdf'>[paper]</a>
</li>
</ul>

	
<strong>-2023-</strong>

<ul><li><p>DemoNSF: A Multi-task Demonstration-based Generative Framework for Noisy Slot Filling Task<br />
<strong>Guanting Dong</strong>, Tingfeng Hui, Zhuoma GongQue, Jinxu Zhao, Daichi Guo, Gang Zhao, Keqing He, Weiran Xu<br />
Findings of EMNLP 2023. 
<a href='https://aclanthology.org/2023.findings-emnlp.705.pdf'>[paper]</a>
<a href='https://github.com/dongguanting/Demo-NSF'>[code]</a>
<a href='https://mp.weixin.qq.com/s/zkdUkybrTafPQR9wpVmi3w'>[blog]</a><br>
	
</li>
</ul>


<ul><li><p>Semantic Parsing by Large Language Models for Intricate Updating Strategies of Zero-Shot Dialogue State Tracking<br />
Yuxiang Wu, <strong>Guanting Dong*</strong>, Weiran Xu<br />
Findings of EMNLP 2023. 
<a href='https://aclanthology.org/2023.findings-emnlp.741.pdf'>[paper]</a>
<a href='https://github.com/ToLightUpTheSky/ParsingDST'>[code]</a> <br>
</li>
</ul>

<ul><li><p>A Multi-Task Semantic Decomposition Framework with Task-specific Pre-training for Few-Shot NER<br />
<strong>Guanting Dong</strong>, Zechen Wang, Jinxu Zhao, Gang Zhao, Daichi Guo, Dayuan Fu, Tingfeng Hui, Chen Zeng, Keqing He, Xuefeng Li, Liwen Wang, Xinyue Cui, Weiran Xu<br />
CIKM 2023 (Oral). 
<a href='https://arxiv.org/pdf/2308.14533.pdf'>[paper]</a>
<a href='https://github.com/dongguanting/MSDP-Fewshot-NER'>[code]</a> <br>
</li>
</ul>


<ul><li><p>Bridging the KB-Text Gap: Leveraging Structured Knowledge-aware Pre-training for KBQA<br />
<strong>Guanting Dong</strong>, Rumei Li, Sirui Wang, Yupeng Zhang, Yunsen Xian, Weiran Xu<br />
CIKM 2023. 
<a href='https://arxiv.org/pdf/2308.14436.pdf'>[paper]</a>
<a href='https://github.com/dongguanting/SKP-for-KBQA'>[code]</a> <br>
</li>
</ul>

<ul><li><p>Revisit Input Perturbation Problems for LLMs: A Unified Robustness Evaluation Framework for Noisy Slot Filling Task<br />
<strong>Guanting Dong</strong>,  Jinxu Zhao, Tingfeng Hui, Daichi Guo, Wenlong Wang, Boqi Feng, Yueyan Qiu, Zhuoma Gongque, Keqing He, Zechen Wang, Weiran Xu<br />
NLPCC 2023 (Oral). 
<a href='https://arxiv.org/pdf/2310.06504.pdf'>[paper]</a>
<a href='https://github.com/dongguanting/Noise-Slot-Filling-LLM'>[code]</a> <br>
</li>
</ul>


<ul><li><p>Generative Zero-Shot Prompt Learning for Cross-Domain Slot Filling with Inverse Prompting<br />
Xuefeng Li, Liwen Wang, <strong>Guanting Dong*</strong>, Keqing He, Jinzheng Zhao, Hao Lei, Jiachi Liu, Weiran Xu<br />
Findings of ACL 2023. 
<a href='https://aclanthology.org/2023.findings-acl.52.pdf'>[paper]</a>
<a href='https://github.com/LiXuefeng2020ai/GZPL'>[code]</a> <br>
</li>
</ul>


<ul><li><p>A Prototypical Semantic Decoupling Method via Joint Contrastive Learning for Few-Shot Named Entity Recognition<br />
<strong>Guanting Dong</strong>, Zechen Wang, Liwen Wang, Daichi Guo, Dayuan Fu, Yuxiang Wu, Chen Zeng, Xuefeng Li, Tingfeng Hui, Keqing He, Xinyue Cui, Qixiang Gao, Weiran Xu<br />
ICASSP 2023. 
<a href='https://ieeexplore.ieee.org/abstract/document/10095149'>[paper]</a>
</li>
</ul>

<ul><li><p>Revisit Out-Of-Vocabulary Problem For Slot Filling: A Unified Contrastive Framework With Multi-Level Data Augmentations<br />
Daichi Guo, <strong>Guanting Dong*</strong>, Dayuan Fu, Yuxiang Wu, Chen Zeng, Tingfeng Hui, Liwen Wang, Xuefeng Li, Zechen Wang, Keqing He, Xinyue Cui, Weiran Xu<br />
ICASSP 2023. 
<a href='https://ieeexplore.ieee.org/abstract/document/10094766/'>[paper]</a>
</li>
</ul>

<strong>-2022-</strong>

<ul><li><p>Exploiting domain-slot related keywords description for Few-Shot Cross-Domain Dialogue State Tracking<br />
Gao Qixiang, <strong>Guanting Dong*</strong>, Yutao Mou, Liwen Wang, Chen Zeng, Daichi Guo, Mingyang Sun, Weiran Xu<br />
EMNLP 2022 (Oral). 
<a href='https://aclanthology.org/2022.emnlp-main.157.pdf'>[paper]</a>
</li>
</ul>


<ul><li><p>Entity-level Interaction via Heterogeneous Graph for Multimodal Named Entity Recognition<br />
Gang Zhao, <strong>Guanting Dong</strong>, Yidong Shi, Haolong Yan, Weiran Xu, Si Li<br />
Findings of EMNLP 2022. 
<a href='https://aclanthology.org/2022.findings-emnlp.473.pdf'>[paper]</a>
<a href='https://github.com/GangZhao98/GEI'>[code]</a> <br>
</li>
</ul>


<ul><li><p>PSSAT: A Perturbed Semantic Structure Awareness Transferring Method for Perturbation-Robust Slot Filling<br />
<strong>Guanting Dong</strong>, Daichi Guo, Liwen Wang, Xuefeng Li, Zechen Wang, Chen Zeng, Keqing He, Jinzheng Zhao, Hao Lei, Xinyue Cui, Yi Huang, Junlan Feng, Weiran Xu<br />
COLING 2022. 
<a href='https://aclanthology.org/2022.coling-1.473.pdf'>[paper]</a>
</li>
</ul>



 -->


<h2>Honors & Awards</h2>
<ul>
    <!-- <li>
        <strong>China National Scholarship</strong>, 2023
    </li> -->
    <li>
        <strong>
            National Scholarship for Master Students(Top 1%)</a>
        </strong>, 2021
    </li>
<!-- 
    <li>
        <strong>Outstanding Graduates of Beijing(Top 1%)</strong>, 2024
    </li>
	
    <li>
        <strong>Outstanding Graduate of Master Students(Top 5%), BUPT.</strong>, 2023
    </li>
    <li>
        <strong>Excellent First-class Scholarship for Master Students, BUPT. (Two times)</strong>, 2021, 2022
    </li>
    <li>
        <strong>
        <a href="http://seretod.org/Challenge.html">1st Award on track 2 of SereTOD Challenge, EMNLP 2022</a>
        </strong>, 2022
    </li>
    <li>
        <strong>Gold Award for College Music Festival Instrumental Performance, Beijing</strong>, 2021
    </li>
    <li>
        <strong>The Mathematical Contest in Modeling, Honorable Mention</strong>, 2021
    </li> -->

</ul>


<h2>Services</h2>
<strong>Reviewer for</strong>:
<ul>
    <li>
        <strong>ICLR 2025</strong>
    </li>
    <li>
        <strong>ACL ARR 2024 August</strong>
    </li>
    <li>
        <strong>ACL ARR 2024 June</strong>
    </li>
</ul>

<div id="footer">
	<div id="footer-text"></div>
</div>
&copy 2024 Dayuan Fu  <br>

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
</script>  
总访问量<span id="busuanzi_value_site_pv"></span>次 <br>
总访客数<span id="busuanzi_value_site_uv"></span>人次 <br>

<!-- <a href="https://clustrmaps.com/site/1blbh"  title="Visit tracker for kunkuang.github.io"><img src="//www.clustrmaps.com/map_v2.png?d=Z8dyJa5Yjz2Z_i_LEAbfY0-TbrPurcZYl5i6ii_5Xbw&cl=ffffff" /></a> -->
</body>

</html>
