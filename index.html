<html>

<head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-EWB73JXBN5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-EWB73JXBN5');
</script>
	
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
	<meta name="description" content="Homepage of Dayuan-Fu">
	<link rel="stylesheet" href="./files/jemdoc.css" type="text/css">
	<title>Dayuan Fu's Homepage|傅大源的个人主页</title>
</head>


<body>

<div id="layout-content" style="margin-top:25px">

<table><tbody><tr>
    <td width="670">
        <div id="toptitle"><h1>Dayuan Fu (傅大源)&nbsp;</h1></div>
        <h3>M.S. Student</h3>  
        <p>
            Dept. of Artificial Intelligence <br>
            Beijing University of Posts and Telecommunications (BUPT) <br>
            Beijing, China. <br>
	    WeChat: fudayuan2000 <br>
            Email:  <a href="mailto:fdy@bupt.edu.cn">fdy@bupt.edu.cn</a> <br>
		
            <a href="https://github.com/Fu-Dayuan">[Github]</a>
            <a href="https://scholar.google.com/citations?hl=zh-CN&user=8t2DPs0AAAAJ">[Google Scholar]</a>
            <a href="https://www.semanticscholar.org/author/Dayuan-Fu/2187926603">[Semantic Scholar]</a> 
            <a href="https://dblp.org/pid/331/3042.html">[DBLP]</a> 

        </p>
    </td>

    <td><img src="./files/photo.jpg" border="0" width="240"></td>
</tr></tbody></table>


<h2>About</h2>
    <p> I am Dayuan Fu, a graduate student at <a href="https://pris-nlp.github.io/en/author/dayuan-fu/">PRIS-NLP Group</a> at Beijing University of Posts and Telecommunications (BUPT), supervised by <a href="https://pris-nlp.github.io/en/author/weiran-xu/">Prof. Weiran Xu.</a> I visited <a href="https://c3i.ee.tsinghua.edu.cn/author/%E5%82%85%E5%A4%A7%E6%BA%90/">TsinghuaC3I group</a> from 2022.10 to 2024.9.  My research interests primarily focus on LLM reasoning, planning, and decision-making ability (in Agent), which can make LLM more universal (i.e. AGI). I have published several papers at prominent NLP conferences, including EMNLP, CIKM, and NAACL.</p>
	    
<h2>News</h2>
<ul>
    <li><strong>[2024-09]</strong> Two papers have been accepted by EMNLP 2024! </li>
    <li><strong>[2024-03]</strong> Two papers have been accepted by NAACL 2024!</li>
<!--     <li><strong>[2024-02]</strong> One paper has been accepted by LREC-COLING 2024! </li> -->
    <li><strong>[2023-08]</strong> One paper has been accepted by CIKM 2023! </li>
    <li><strong>[2024-02]</strong> One paper have been accepted by NAACL 2024! </li>
<!--     <li><strong>[2023-02]</strong> Two papers have been accepted by ICASSP 2023! </li> -->
    <li><strong>[2022-10]</strong> One paper has been accepted at the SereTOD 2022 Workshop, EMNLP 2022! </li>
    <li><strong>[2022-09]</strong> Achieved the 1st rank on SereTOD 2022 track 2, EMNLP 2022!</li>
</ul>
    


<h2>Experiences</h2>
	<strong>Academia</strong>
	<ul>
        <li>[2023.9 - Now]<img style="width: 1em;"src="./files/bupt.webp"> M.S. at Beijing University of Posts and Telecommunications</li>
	    <li>[2019.9 - 2023.6] <img style="width: 1em;"src="./files/bupt.webp"> B.S. at Beijing University of Posts and Telecommunications</li>
        <li>[2022.9 - 2023.9] <img style="width: 1em;"src="./files/C3I.png"> Visiting student at TsinghuaC3I, Tsinghua University</li>
</ul>
	
 	<strong>Industry</strong>
	<ul>
	<li>[2024.1 - Now] <img style="width: 2.4em;"src="./files/meituan.png"> Meituan, NLP Center, Research Intern on Agent and data synthesis.</li>
</ul>

<h2>Featured Preprints</h2>
	
<strong>-2024-</strong>


<ul><li><p> AgentRefine: Enhancing Agent Generalization through Refinement Tuning <br />
    <strong>Dayuan Fu</strong>, Keqing He, Yejie Wang, Wentao Hong, Zhuoma Gongque, Weihao Zeng, Wei Wang, Jingang Wang, Xunliang Cai, Weiran Xu<br />
    ICLR 2025 Submission.
    <a href='https://openreview.net/forum?id=FDimWzmcWn'>[paper]</a >
</li>
</ul>


<ul><li><p> PreAct: Prediction Enhances Agent's Planning Ability <br />
    <strong>Dayuan Fu</strong>, Jianzhao Huang, Siyuan Lu, Guanting Dong, Yejie Wang, Keqing He, Weiran Xu <br />
    Arxiv
    <a href='https://arxiv.org/abs/arXiv:2402.11534'>[paper]</a >
    <a href='https://mp.weixin.qq.com/s/1R_0Q57_vu9uGr_3j0Ozwg'>[blog]</a><br>
</li>
</ul>


<ul><li><p> CS-Bench: A Comprehensive Benchmark for Large Language Models towards Computer Science Mastery <br />
    Xiaoshuai Song, Muxi Diao, Guanting Dong, Zhengyang Wang, Yujia Fu, Runqi Qiao, Zhexu Wang, <strong>Dayuan Fu</strong>, Huangxuan Wu, Bin Liang, Weihao Zeng, Yejie Wang, Zhuoma GongQue, Jianing Yu, Qiuna Tan, Weiran Xu<br />
    Arxiv
    <a href='https://arxiv.org/pdf/2406.08587'>[paper]</a >
    <a href='https://csbench.github.io/'>[website]</a >
    <a href='https://github.com/csbench/csbench'>[code]</a >
    <a href='https://huggingface.co/datasets/CS-Bench/CS-Bench'>[dataset]</a >
    <a href='https://mp.weixin.qq.com/s/9DDSbKJt3rYisJi95fJ46w'>[blog]</a><br>
</li>
</ul>

<ul><li><p> What Composes Embodied Agent Performance? A Comprehensive Study of Capability Mixture for Agent Tuning <br />
    <strong>Dayuan Fu</strong>, Keqing He, Guanting Dong, Chao Wang, Zhuoma GongQue, Jianzhao Huang, Heyang Xu, Zhexu Wang, Muxi Diao, Yejie Wang, Zhengyang Wang, Jingang Wang, Xunliang Cai, Weiran Xu <br />
    Under review
</li>
</ul>

	
<h2>Selected Publications</h2>

(* denotes equal contributions)<br>
<strong>-2024-</strong>

<ul><li><p> <img style="width: 1em;"src="./files/C3I.png"> MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making <br />
    <strong>Dayuan Fu</strong>, Biqing Qi, Yihuai Gao, Che Jiang, Guanting Dong, Bowen Zhou<br />
    EMNLP 2024 Main 
    <a href='https://arxiv.org/abs/2409.16686'>[paper]</a >
</li>
</ul>

<ul><li><p> How Do Your Code LLMs Perform? Empowering Code Instruction Tuning with High-Quality Data <br />
    Yejie Wang*, Keqing He*, <strong>Dayuan Fu*</strong>, Zhuoma Gongque, Heyang Xu, Yanxu Chen, Zhexu Wang, Yujia Fu, Guanting Dong, Muxi Diao, Jingang Wang, Mengdi Zhang, Xunliang Cai, Weiran Xu<br />
    EMNLP 2024 Main 
    <a href='https://arxiv.org/abs/2409.16686'>[paper]</a >
</li>
</ul>

<ul><li><p> <img style="width: 1em;"src="./files/C3I.png"> On Large Language Models' Hallucination with Regard to Known Facts <br />
    Che Jiang, Biqing Qi, Xiangyu Hong, <strong>Dayuan Fu</strong>, Yang Cheng, Fandong Meng, Mo Yu, Bowen Zhou, Jie Zhou<br />
    NAACL 2024 Main
    <a href='https://arxiv.org/abs/2403.20009'>[paper]</a >
</li>
</ul>


<ul><li><p>  DivTOD: Unleashing the Power of LLMs for Diversifying Task-Oriented Dialogue Representations <br />
    Weihao Zeng*, <strong>Dayuan Fu*</strong>, Keqing He, Yejie Wang, Yukai Xu, Weiran Xu<br />
    NAACL 2024 Findings
    <a href='https://arxiv.org/abs/2404.00557'>[paper]</a >
</li>
</ul>

<strong>-2023-</strong>

<ul><li><p> A Multi-Task Semantic Decomposition Framework with Task-specific Pre-training for Few-Shot NER <br />
    Guanting Dong, Zechen Wang, Jinxu Zhao, Gang Zhao, Daichi Guo, <strong>Dayuan Fu</strong>, Tingfeng Hui, Chen Zeng, Keqing He, Xuefeng Li, Liwen Wang, Xinyue Cui, Weiran Xu<br />
    CIKM 2023 (Oral). 
    <a href='https://arxiv.org/pdf/2308.14533.pdf'>[paper]</a>
    <a href='https://github.com/dongguanting/MSDP-Fewshot-NER'>[code]</a> <br>
</li>
</ul>

<strong>-2022-</strong>

<ul><li><p> Semi-supervised knowledge-grounded pre-training for task-oriented dialog systems <br />
    Weihao Zeng, Keqing He, Zechen Wang, <strong>Dayuan Fu</strong>, Guanting Dong, Ruotong Geng, Pei Wang, Jingang Wang, Chaobo Sun, Wei Wu, Weiran Xu<br />
    SereTOD 2022 Workshop, EMNLP 2022, the 1st Award on SereTOD Challenge 2022 track 2
    <a href='https://arxiv.org/abs/2210.08873'>[paper]</a>
</li>
</ul>

<h2>Honors & Awards</h2>
<ul>
    <!-- <li>
        <strong>China National Scholarship</strong>, 2023
    </li> -->
    <li>
        <strong>Excellent First-class Scholarship for Master Students, BUPT.</strong>, 2023
    </li>
    <li>
        <strong>
            the 1st Award on SereTOD Challenge 2022 track 2</a>
        </strong>, 2022
    </li>
    <li>
        <strong>
            National Scholarship(Top 1%)</a>
        </strong>, 2021
    </li>
    <li>
        <strong>
            First Prize in The Chinese Mathematics Competitions(Three times)</a>
        </strong>, 2020,2021,2022
    </li>
<!-- The Chinese Mathematics Competitions 
    <li>
        <strong>Outstanding Graduates of Beijing(Top 1%)</strong>, 2024
    </li>
	
    <li>
        <strong>Outstanding Graduate of Master Students(Top 5%), BUPT.</strong>, 2023
    </li>
    <li>
        <strong>Excellent First-class Scholarship for Master Students, BUPT. (Two times)</strong>, 2021, 2022
    </li>
    <li>
        <strong>
        <a href="http://seretod.org/Challenge.html">1st Award on track 2 of SereTOD Challenge, EMNLP 2022</a>
        </strong>, 2022
    </li>
    <li>
        <strong>Gold Award for College Music Festival Instrumental Performance, Beijing</strong>, 2021
    </li>
    <li>
        <strong>The Mathematical Contest in Modeling, Honorable Mention</strong>, 2021
    </li> -->

</ul>


<h2>Services</h2>
<strong>Reviewer for</strong>:
<ul>
    <li>
        <strong>ICLR 2025</strong>
    </li>
    <li>
        <strong>ACL ARR 2024 August</strong>
    </li>
    <li>
        <strong>ACL ARR 2024 June</strong>
    </li>
</ul>

<div id="footer">
	<div id="footer-text"></div>
</div>
&copy 2024 Dayuan Fu  <br>

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
</script>  
总访问量<span id="busuanzi_value_site_pv"></span>次 <br>
总访客数<span id="busuanzi_value_site_uv"></span>人次 <br>

<!-- <a href="https://clustrmaps.com/site/1blbh"  title="Visit tracker for kunkuang.github.io"><img src="//www.clustrmaps.com/map_v2.png?d=Z8dyJa5Yjz2Z_i_LEAbfY0-TbrPurcZYl5i6ii_5Xbw&cl=ffffff" /></a> -->
</body>

</html>
